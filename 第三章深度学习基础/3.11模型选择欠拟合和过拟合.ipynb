{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "笔记：\n",
    "    1.训练误差和泛化误差  训练数据集上的误差；任意一个测试集上的误差期望\n",
    "    2.机器学习基本假设:样本独立同分布假设\n",
    "    3.模型选择：验证数据集 k折交叉验证\n",
    "    4.欠拟合：训练误差高，过拟合：训练误差远小于测试误差\n",
    "       模型复杂度、训练数据集大小"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import d2lzh as d2l\n",
    "from mxnet import autograd, gluon,nd\n",
    "from mxnet.gluon import data as gdata, loss as gloss, nn\n"
   ]
  },
  {
   "source": [
    "1.生成数据集"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train, n_test, true_w, true_b = 100, 100, [1.2, -3.4, 5.6], 5\n",
    "features = nd.random.normal(shape = (n_train + n_test, 1 ))\n",
    "\n",
    "poly_features = nd.concat(features, nd.power(features,2),\n",
    "nd.power(features,3))\n",
    "\n",
    "labels = (true_w[0] * poly_features[:, 0] + true_w[1] * poly_features[:, 1]\n",
    "+ true_w[2] * poly_features[:, 2] + true_b)\n",
    "\n",
    "labels += nd.random.normal(scale = 0.1, shape = labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(\n",
       " [[2.2122064]\n",
       "  [0.7740038]]\n",
       " <NDArray 2x1 @cpu(0)>,\n",
       " \n",
       " [[ 2.2122064   4.893857   10.826221  ]\n",
       "  [ 0.7740038   0.5990819   0.46369165]]\n",
       " <NDArray 2x3 @cpu(0)>,\n",
       " \n",
       " [51.674885   6.3585763]\n",
       " <NDArray 2 @cpu(0)>)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "features[:2], poly_features[:2], labels[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2定义、训练和测试模型\n",
    "def semilogy(x_vals, y_vals, x_labels, y_labels, x2_vals = None, y2_vals = None,legend = None, figsize = (3.5, 2.5)):\n",
    "    d2l.set_figsize(figsize)\n",
    "    d2l.plt.xlabel(x_label)\n",
    "    d2l.plt.ylabel(y_label)\n",
    "    d2l.plt.semilogy(x_vals,y_vals)\n",
    "    if x2_vals and y2_vals:\n",
    "        d2l.plt.semilogy(x2_vals, y2_vals, linestyle = ':')\n",
    "        d2l.plt.legend(legend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs, loss = 100, gloss.L2Loss()\n",
    "\n",
    "def fit_and_plot(train_features, test_features, train_labels, test_labels):\n",
    "    net = nn.Sequential()\n",
    "    net.add(nn.Dense(1))\n",
    "    net.initialize()\n",
    "    batch_size = min(10, train_labels.shape[0])\n",
    "    train_iter = gdata.DataLoader(gdata.ArrayDataset(train_features, train_labels), batch_size, shuffle = True)\n",
    "    trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate' : 0.01})\n",
    "\n",
    "    train_ls.test_ls = [],[]\n",
    "    for _ in range(num_epochs):\n",
    "        for X,y in train_iter:\n",
    "            with autograd.record:\n",
    "                l = loss(net(X), y)\n",
    "            l.backward()\n",
    "            trainer.step(batch_size)\n",
    "        train_ls.append(loss(net(train_features),\n",
    "        train_labels).mean().asscalar())\n",
    "        test_ls.append(loss(net(test_features),\n",
    "        test_labels).mean().asscalar())\n",
    "    print('final  epoch: train loss', train_ls[-1],'test loss',test_ls[-1])\n",
    "    semilogy(range(1, num_epochs + 1), train_ls, 'epochs', 'loss',\n",
    "    range(1,num_epochs + 1), test_ls, ['train', 'test'])\n",
    "    print('weight', net[0].weight.data().asnumpy(),\n",
    "    '\\nbias:', net[0].bias.data().asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}